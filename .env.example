# Polishing Configuration
# Set to true to enable GPT polishing (requires OpenAI API key)
# Set to false for local-only transcription (no API key needed)
ENABLE_POLISHING=false

# Auto-Paste Configuration
# Set to true to automatically paste transcription (requires xdotool)
# Set to false to only copy to clipboard
AUTO_PASTE=true

# OpenAI API Configuration (only required if ENABLE_POLISHING=true)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# Whisper Model Configuration
# Options: tiny, base, small, medium, large-v3
# small = ~500MB, good balance of speed and accuracy
WHISPER_MODEL=small

# Model Cache Directory (optional)
# Default: ~/.cache/huggingface/hub/
# Set this to use a custom location (e.g., on faster SSD)
# HF_HOME=/path/to/custom/cache

# Device Configuration
# Options: cpu, cuda
DEVICE=cpu

# Compute Type
# Options: int8 (fastest), float16, float32
COMPUTE_TYPE=int8

# OpenAI Model (only used if ENABLE_POLISHING=true)
# Options: gpt-4o-mini, gpt-4o, gpt-4-turbo
OPENAI_MODEL=gpt-4o-mini

# Daemon Idle Timeout (in seconds)
# Model stays loaded in VRAM for this duration after last use
# Set to 0 to keep loaded indefinitely (recommended for systemd auto-start)
# Set to 600 (10 min) for manual hotkey-only use to free VRAM when idle
IDLE_TIMEOUT=600  # 10 minutes (use 0 for always-on daemon)
